import requests
import pandas as pd
import time
from datetime import datetime, timedelta
from supabase import create_client
import os
import supabase

from utils_backfill import flatten_vacancy, extract_regions_and_cities_recursive, load_regions_and_cities_from_api, get_all_vacancies_for_params

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å email!
headers = {
    "User-Agent": "MemeWeather-HH-Pipeline/1.0 (oborisov.personal@gmail.com)"
}

''' def flatten_vacancy(v):
    flat = {}

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
    flat["id"] = v.get("id")
    flat["name"] = v.get("name")
    flat["published_at"] = v.get("published_at")
    flat["created_at"] = v.get("created_at")
    flat["url"] = v.get("alternate_url")
    flat["archived"] = v.get("archived", False)

    # –ì–æ—Ä–æ–¥
    area = v.get("area") or {}
    flat["area_id"] = area.get("id")
    flat["area_name"] = area.get("name")

    # –ó–∞—Ä–ø–ª–∞—Ç–∞
    salary = v.get("salary") or {}
    flat["salary_from"] = salary.get("from")
    flat["salary_to"] = salary.get("to")
    flat["salary_currency"] = salary.get("currency")
    flat["salary_gross"] = salary.get("gross")

    # –†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å
    employer = v.get("employer") or {}
    flat["employer_name"] = employer.get("name")
    flat["employer_id"] = employer.get("id")

    # –û–ø—ã—Ç, –∑–∞–Ω—è—Ç–æ—Å—Ç—å, –≥—Ä–∞—Ñ–∏–∫
    exp = v.get("experience") or {}
    emp = v.get("employment") or {}
    sched = v.get("schedule") or {}
    flat["experience_name"] = exp.get("name")
    flat["employment_name"] = emp.get("name")
    flat["schedule_name"] = sched.get("name")

    # –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–æ–ª—å (–±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é)
    roles = v.get("professional_roles") or []
    flat["role_name"] = roles[0].get("name") if roles else None
    flat["role_id"] = roles[0].get("id") if roles else None

    return flat 

def extract_regions_and_cities_recursive(areas, regions_list, cities_list):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ä–µ–≥–∏–æ–Ω–æ–≤ (—É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å 'areas') –∏ –∫–æ–Ω–µ—á–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ (—É –∫–æ—Ç–æ—Ä—ã—Ö 'areas' –ø—É—Å—Ç–æ–π).
    """
    for area in areas:
        if area.get("areas"):  # –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–¥–æ–±–ª–∞—Å—Ç–∏ ‚Äî —ç—Ç–æ —Ä–µ–≥–∏–æ–Ω
            regions_list.append(area["id"])
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–¥—ë–º –≤ –ø–æ–¥–æ–±–ª–∞—Å—Ç–∏
            extract_regions_and_cities_recursive(area["areas"], regions_list, cities_list)
        else:  # –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥–æ–±–ª–∞—Å—Ç–µ–π ‚Äî —ç—Ç–æ –∫–æ–Ω–µ—á–Ω—ã–π –≥–æ—Ä–æ–¥
            cities_list.append(area["id"])

def load_regions_and_cities_from_api():
    url = "https://api.hh.ru/areas/113"
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ –≥–æ—Ä–æ–¥–æ–≤: {response.status_code}")
        return [], []
    data = response.json()
    regions_list = []
    cities_list = []
    extract_regions_and_cities_recursive(data["areas"], regions_list, cities_list)
    return regions_list, cities_list

def get_all_vacancies_for_params(city_id, search_text, date_from=None, date_to=None):
    url = "https://api.hh.ru/vacancies"
    params = {
        "text": search_text,
        "area": city_id,
        "per_page": 100,
        "page": 0,
        "search_field": "name"
    }
    if date_from:
        params["date_from"] = date_from
    if date_to:
        params["date_to"] = date_to

    all_vacancies = []
    page = 0
    max_pages = 20  # hh.ru –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–∫—Å–∏–º—É–º 20 —Å—Ç—Ä–∞–Ω–∏—Ü (2000 –≤–∞–∫–∞–Ω—Å–∏–π)

    while page < max_pages:
        params["page"] = page
        response = requests.get(url, headers=headers, params=params)
        
        if response.status_code != 200:
            print(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –ø—Ä–∏ area={city_id}, text='{search_text}', date_from={date_from}, date_to={date_to}: {response.status_code}")
            break
            
        data = response.json()
        vacancies = data["items"]
        if not vacancies:
            break
            
        all_vacancies.extend(vacancies)
        print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} (area={city_id}, text='{search_text}', date_from={date_from}, date_to={date_to}): –ø–æ–ª—É—á–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π (–≤—Å–µ–≥–æ: {len(all_vacancies)})")
        
        page += 1
        time.sleep(0.5)  # —É–≤–∞–∂–∞–µ–º API

    print(f"‚úÖ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ area={city_id}, text='{search_text}', date_from={date_from}, date_to={date_to}: {len(all_vacancies)}")
    return all_vacancies '''

# === –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ ===
print("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ API...")
all_regions, all_cities = load_regions_and_cities_from_api()

print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_regions)} —Ä–µ–≥–∏–æ–Ω–æ–≤, {len(all_cities)} –∫–æ–Ω–µ—á–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤.")

# –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≥–æ—Ä–æ–¥–æ–≤-–º–∏–ª–ª–∏–æ–Ω–Ω–∏–∫–æ–≤ (–∏–∑ —Ç–≤–æ–µ–≥–æ —Å—Ç–∞—Ä–æ–≥–æ cMillioners)
cMillioners = [1, 2, 1057, 3, 1130, 54, 1679, 139, 1321, 1438, 1586, 1420, 1249, 1844, 1317, 1511]

# –°–æ–∑–¥–∞—ë–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫: –≥–æ—Ä–æ–¥–∞-–º–∏–ª–ª–∏–æ–Ω–Ω–∏–∫–∏ + –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã
cMillioners_extended = cMillioners + all_regions

print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ area_id: {len(cMillioners)} –≥–æ—Ä–æ–¥–æ–≤ + {len(all_regions)} —Ä–µ–≥–∏–æ–Ω–æ–≤ = {len(cMillioners_extended)} —Å—É—â–Ω–æ—Å—Ç–µ–π.")

all_vacancies = []
seen_ids = set()
# --- –ù–û–í–û–ï: –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è "–≥–æ—Ä—è—á–∏—Ö" —Ä–µ–≥–∏–æ–Ω–æ–≤ ---
hot_areas = set()

search_texts = ["–∞–Ω–∞–ª–∏—Ç–∏–∫", "analytic"]

# --- –®–∞–≥ 1: –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ö–≤–∞—Ç –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–∞—Ö –∏ —Ä–µ–≥–∏–æ–Ω–∞—Ö ---
print("\nüîç –®–∞–≥ 1: –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ö–≤–∞—Ç –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –≥–æ—Ä–æ–¥–∞—Ö –∏ —Ä–µ–≥–∏–æ–Ω–∞—Ö...")
for search_text in search_texts:
    for area_id in cMillioners_extended:
        vacancies_batch = get_all_vacancies_for_params(area_id, search_text)
        for v in vacancies_batch:
            if v["id"] not in seen_ids:
                all_vacancies.append(v)
                seen_ids.add(v["id"])

        # --- –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 2000 –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ hot_areas ---
        if len(vacancies_batch) == 2000:
            hot_areas.add(area_id)
        # --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û ---


# --- –®–∞–≥ 1.5: "–î–æ–∫–æ–ø–∫–∞" –≤ "–≥–æ—Ä—è—á–∏—Ö" —Ä–µ–≥–∏–æ–Ω–∞—Ö –∏–∑ –®–∞–≥–∞ 1 ---
print("\nüîç –®–∞–≥ 1.5: –î–æ–∫–æ–ø–∫–∞ –≤ '–≥–æ—Ä—è—á–∏—Ö' —Ä–µ–≥–∏–æ–Ω–∞—Ö –∏–∑ –®–∞–≥–∞ 1...")
for area_id in hot_areas:
    print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ '–≥–æ—Ä—è—á–µ–≥–æ' —Ä–µ–≥–∏–æ–Ω–∞: area_id={area_id}")
    for search_text in search_texts:
        print(f"    –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è '{search_text}' –≤ area_id={area_id}...")
        current_start = datetime(2024, 1, 1)
        end_date = datetime.today()
        delta = timedelta(days=7)

        while current_start < end_date:
            current_end = min(current_start + delta - timedelta(days=1), end_date)

            date_from_str = current_start.strftime("%Y-%m-%d")
            date_to_str = current_end.strftime("%Y-%m-%d")

            print(f"      –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {date_from_str} - {date_to_str} –¥–ª—è area_id={area_id}")
            time_batch = get_all_vacancies_for_params(area_id, search_text, date_from=date_from_str, date_to=date_to_str)

            for v in time_batch:
                if v["id"] not in seen_ids:
                    all_vacancies.append(v)
                    seen_ids.add(v["id"])

            current_start += delta


# --- –®–∞–≥ 2: "–î–æ–∫–æ–ø–∫–∞" –≤ "–≥–æ—Ä—è—á–∏—Ö" —Ä–µ–≥–∏–æ–Ω–∞—Ö (–†–æ—Å—Å–∏—è —Ü–µ–ª–∏–∫–æ–º) —á–µ—Ä–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ---
print("\nüîç –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ '–¥–æ–∫–æ–ø–∫–∏' –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è area=113...")
for search_text in search_texts:
    print(f"  –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è '{search_text}'...")
    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ–π –†–æ—Å—Å–∏–∏
    general_batch = get_all_vacancies_for_params(113, search_text)
    
    if len(general_batch) == 2000:
        print(f"    -> –ù–∞–π–¥–µ–Ω–æ —Ä–æ–≤–Ω–æ 2000 –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è '{search_text}'. –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
        start_date = datetime(2024, 1, 1)
        end_date = datetime.today() # –∏–ª–∏ datetime(2024, 10, 23), –µ—Å–ª–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–∞—Ç–∞ –≤–∞–∂–Ω–∞
        delta = timedelta(days=7)

        current_start = start_date
        while current_start < end_date:
            current_end = min(current_start + delta - timedelta(days=1), end_date)
            
            date_from_str = current_start.strftime("%Y-%m-%d")
            date_to_str = current_end.strftime("%Y-%m-%d")
            
            print(f"      –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {date_from_str} - {date_to_str}")
            time_batch = get_all_vacancies_for_params(113, search_text, date_from=date_from_str, date_to=date_to_str)
            
            for v in time_batch:
                if v["id"] not in seen_ids:
                    all_vacancies.append(v)
                    seen_ids.add(v["id"])
            
            current_start += delta
    else:
        print(f"    -> –ù–∞–π–¥–µ–Ω–æ {len(general_batch)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è '{search_text}'. –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ù–ï —Ç—Ä–µ–±—É–µ—Ç—Å—è.")


# --- –®–∞–≥ 3: –û—Ö–≤–∞—Ç "–æ—Å—Ç–∞–ª—å–Ω—ã—Ö" –≤–∞–∫–∞–Ω—Å–∏–π, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å area=113 (–≤—Å—è –†–æ—Å—Å–∏—è) ---
# (–¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ù–ï –∑–∞–ø—É—Å–∫–∞–ª–æ—Å—å)
for search_text in search_texts:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—Å–∫–∞–ª–æ—Å—å –ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ search_text
    # (–ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Å–¥–µ–ª–∞—Ç—å –±–æ–ª–µ–µ —è–≤–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Ñ–ª–∞–≥)
    # –ü—Ä–æ–≤–µ—Ä–∏–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –≤ general_batch –¥–ª—è —ç—Ç–æ–≥–æ search_text
    # –ù–æ –ø—Ä–æ—â–µ –æ–¥–∏–Ω —Ä–∞–∑ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å area=113 –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å,
    # —á—Ç–æ–±—ã –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å –ª–æ–≥–∏–∫—É, –µ—Å–ª–∏ –º—ã —É–∂–µ –≤—Å—ë —Å–æ–±—Ä–∞–ª–∏ —á–µ—Ä–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏–µ.
    # –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ù–ï –∑–∞–ø—É—Å–∫–∞–ª–æ—Å—å, —ç—Ç–æ—Ç —à–∞–≥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω.
    # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –º—ã –≤—ã–ø–æ–ª–Ω–∏–º –µ–≥–æ –≤—Å–µ–≥–¥–∞, –Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ seen_ids.
    # –≠—Ç–æ –Ω–µ –¥–æ–±–∞–≤–∏—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π, –µ—Å–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏—Ç –ø–æ–ª–Ω–æ—Ç—É, –µ—Å–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ.
    print(f"\nüîç –®–∞–≥ 3: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ area=113 –¥–ª—è '{search_text}' (–¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –≤–∞–∫–∞–Ω—Å–∏–π, –µ—Å–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ)...")

    url = "https://api.hh.ru/vacancies"
    params = {
        "text": search_text,
        "area": 113, # –í—Å—è –†–æ—Å—Å–∏—è
        "per_page": 100,
        "page": 0,
        "search_field": "name"
    }

    extra_batch = []
    page = 0
    max_pages = 20

    while page < max_pages:
        params["page"] = page
        response = requests.get(url, headers=headers, params=params)
        
        if response.status_code != 200:
            print(f"    –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –ø—Ä–∏ area=113, text='{search_text}': {response.status_code}")
            break
            
        data = response.json()
        vacancies = data["items"]
        if not vacancies:
            break

        # –§–∏–ª—å—Ç—Ä—É–µ–º:
        # 1. area_id –Ω–µ –≤ cMillioners_extended (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –®–∞–≥ 1)
        # 2. id –Ω–µ –≤ seen_ids
        # 3. id —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –≤–∞–∫–∞–Ω—Å–∏–∏
        for v in vacancies:
            v_id = v.get("id")
            v_area_id = v.get("area_id")
            if v_area_id not in cMillioners_extended and v_id is not None and v_id not in seen_ids:
                all_vacancies.append(v)
                seen_ids.add(v_id)
                extra_batch.append(v)

        print(f"    –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} (area=113, text='{search_text}'): –ø–æ–ª—É—á–µ–Ω–æ {len(vacancies)}, –¥–æ–±–∞–≤–ª–µ–Ω–æ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ area –∏ id): {len([v for v in vacancies if v.get('area_id') not in cMillioners_extended and v.get('id') is not None and v.get('id') not in seen_ids])}")
        page += 1
        time.sleep(0.5)

    print(f"    ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ '–æ—Å—Ç–∞–ª—å–Ω—ã—Ö' (area=113, —Ñ–∏–ª—å—Ç—Ä –ø–æ area –∏ id) –¥–ª—è '{search_text}': {len(extra_batch)}")


# --- –®–∞–≥ 4: –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (—É–∂–µ —á–∞—Å—Ç–∏—á–Ω–æ —Å–¥–µ–ª–∞–Ω–∞ —á–µ—Ä–µ–∑ seen_ids) ---
print(f"\n‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ—Å–ª–µ –≤—Å–µ—Ö —à–∞–≥–æ–≤: {len(all_vacancies)}")

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
flattened = [flatten_vacancy(v) for v in all_vacancies]
df = pd.DataFrame(flattened)

print(df.head())

FinalDF = df.pipe(lambda x: x
    .astype({
        "salary_from": "Int64",
        "salary_to": "Int64", 
        "id": "int64"
    })
    .drop(columns=['area_id', 'employer_id', 'role_id'])
    .drop_duplicates()
    .assign(salary_gross=lambda x: x["salary_gross"].map({
        True: True,
        False: False,
        "true": True, 
        "false": False,
        None: None
    }).astype("boolean"))
)


supabase = create_client(os.environ["SUPABASE_URL"], os.environ["SUPABASE_KEY"])
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π
records = FinalDF.to_dict(orient="records")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å upsert –ø–æ id
try:
    supabase.table("hh_vacancies").upsert(records, on_conflict="id").execute()
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(records)} –≤–∞–∫–∞–Ω—Å–∏–π –≤ Supabase")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
