import requests
import time
from datetime import datetime, timedelta
from supabase import create_client
import os
import pytz # pip install pytz
import pandas as pd # pip install pandas
import sys
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from utils.utils_daily import load_regions_and_cities_from_api, flatten_vacancy, get_vacancies_for_date

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
headers = {"User-Agent": "MemeWeather-HH-Pipeline/1.0 (oborisov.personal@gmail.com)"}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Supabase (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–¥–∞–Ω—ã)
supabase = create_client(os.environ["SUPABASE_URL"], os.environ["SUPABASE_KEY"])

# –ì–æ—Ä–æ–¥–∞-–º–∏–ª–ª–∏–æ–Ω–Ω–∏–∫–∏ + —Ä–µ–≥–∏–æ–Ω—ã (–∫–∞–∫ –≤ backfill)
cMillioners = [1, 2, 1057, 3, 1130, 54, 1679, 139, 1321, 1438, 1586, 1420, 1249, 1844, 1317, 1511]

# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ (–∫–∞–∫ –≤ backfill) - —É–±—Ä–∞–Ω—ã –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
''' def load_regions_and_cities_from_api():
    url = "https://api.hh.ru/areas/113"  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–≥–∏–æ–Ω–æ–≤: {response.status_code}")
        return []
    data = response.json()
    regions = []
    def extract_regions(areas):
        for area in areas:
            if area.get("areas"):
                regions.append(area["id"])
                extract_regions(area["areas"])
    extract_regions(data["areas"])
    return regions '''

all_regions = load_regions_and_cities_from_api()
cMillioners_extended = list(set(cMillioners + all_regions))

# === –í—á–µ—Ä–∞—à–Ω—è—è –¥–∞—Ç–∞ (—Å —É—á—ë—Ç–æ–º –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏) ===
moscow_tz = pytz.timezone('Europe/Moscow')
yesterday = (datetime.now(moscow_tz) - timedelta(days=1)).strftime("%Y-%m-%d")
print(f"–°–æ–±–∏—Ä–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –∑–∞: {yesterday}")

# === –§—É–Ω–∫—Ü–∏—è —Å–±–æ—Ä–∞ ===
''' def get_vacancies_for_date(area_id, date_str, search_text="–∞–Ω–∞–ª–∏—Ç–∏–∫"): # –î–æ–±–∞–≤–ª–µ–Ω search_text
    url = "https://api.hh.ru/vacancies"  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã
    params = {
        "text": search_text,
        "area": area_id,
        "search_field": "name",
        "date_from": date_str,
        "date_to": date_str,
        "per_page": 100,
        "page": 0
    }
    all_vac = []
    page = 0
    while page < 20:
        params["page"] = page
        # print(f"    –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page} –¥–ª—è area_id={area_id}, date={date_str}, text={search_text}...") # –£–±—Ä–∞–Ω–æ
        resp = requests.get(url, headers=headers, params=params)
        if resp.status_code != 200:
            print(f"    –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ area_id={area_id}, date={date_str}, text={search_text}, page={page}: {resp.status_code}") # –û—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –æ—à–∏–±–æ–∫ API
            break
        data = resp.json()
        if not data["items"]:
            # print(f"    –ù–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –¥–ª—è area_id={area_id}, date={date_str}, text={search_text}.") # –£–±—Ä–∞–Ω–æ
            break
        all_vac.extend(data["items"])
        # print(f"    –ü–æ–ª—É—á–µ–Ω–æ {len(data['items'])} –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –¥–ª—è area_id={area_id}, date={date_str}, text={search_text}. –í—Å–µ–≥–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–æ: {len(all_vac)}") # –£–±—Ä–∞–Ω–æ
        page += 1
        time.sleep(0.3)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª–∏–º–∏—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if len(all_vac) == 2000:
        print(f"‚ö†Ô∏è  –í–æ–∑–º–æ–∂–µ–Ω –ª–∏–º–∏—Ç 2000 –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è area_id={area_id}, date={date_str}, text={search_text}")
        
    return all_vac '''

# === –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä ===
all_vacancies = []
seen_ids = set()

search_texts = ["–∞–Ω–∞–ª–∏—Ç–∏–∫", "analytic"] # –î–æ–±–∞–≤–ª–µ–Ω "analytic"

for search_text in search_texts:
    # print(f"--- –°–±–æ—Ä –¥–ª—è —Ç–µ–∫—Å—Ç–∞: {search_text} ---") # –£–±—Ä–∞–Ω–æ
    # –î–æ–±–∞–≤–∏–º —Å—á—ë—Ç—á–∏–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    area_counter = 0
    total_areas = len(cMillioners_extended)
    for area_id in cMillioners_extended:
        area_counter += 1
        # print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ area_id {area_id} ({area_counter}/{total_areas}) –¥–ª—è '{search_text}'...") # –£–±—Ä–∞–Ω–æ
        batch = get_vacancies_for_date(area_id, yesterday, search_text)
        for v in batch:
            if v["id"] not in seen_ids:
                all_vacancies.append(v)
                seen_ids.add(v["id"])
        # (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –í—ã–≤–µ—Å—Ç–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π, —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–ª—è —ç—Ç–æ–≥–æ area_id
        # print(f"    -> –°–æ–±—Ä–∞–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è area_id {area_id}: {len([v for v in batch if v['id'] not in seen_ids])} (–Ω–æ–≤—ã—Ö: –¥–æ —ç—Ç–æ–≥–æ –±—ã–ª–æ {len(seen_ids) - len([v for v in batch if v['id'] not in seen_ids])})") # –£–±—Ä–∞–Ω–æ

    # –®–∞–≥ 2: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤—Å–µ–π –†–æ—Å—Å–∏–∏ (area=113)
    # print(f"  –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ area=113 –¥–ª—è '{search_text}'...") # –£–±—Ä–∞–Ω–æ
    batch = get_vacancies_for_date(113, yesterday, search_text)
    initial_seen_count = len(seen_ids)
    for v in batch:
        if v["id"] not in seen_ids:
            all_vacancies.append(v)
            seen_ids.add(v["id"])
    final_seen_count = len(seen_ids)
    # print(f"    -> –°–æ–±—Ä–∞–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è area=113: {len(batch)} (–Ω–æ–≤—ã—Ö: {final_seen_count - initial_seen_count})") # –£–±—Ä–∞–Ω–æ

print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π. –û–±—Ä–∞–±–æ—Ç–∫–∞...")

# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ ===
''' def flatten_vacancy(v):
    flat = {}
    flat["id"] = int(v["id"])
    flat["name"] = v.get("name")
    flat["published_at"] = v.get("published_at")
    flat["created_at"] = v.get("created_at")
    flat["url"] = v.get("alternate_url")
    flat["archived"] = v.get("archived", False)
    flat["area_name"] = v.get("area", {}).get("name")
    salary = v.get("salary") or {}
    flat["salary_from"] = salary.get("from")
    flat["salary_to"] = salary.get("to")
    flat["salary_currency"] = salary.get("currency")
    flat["salary_gross"] = salary.get("gross")
    flat["employer_name"] = v.get("employer", {}).get("name")
    flat["experience_name"] = v.get("experience", {}).get("name")
    flat["employment_name"] = v.get("employment", {}).get("name")
    flat["schedule_name"] = v.get("schedule", {}).get("name")
    roles = v.get("professional_roles") or []
    flat["role_name"] = roles[0].get("name") if roles else None
    # –î–æ–±–∞–≤–∏–º area_id, employer_id, role_id, —á—Ç–æ–±—ã –∏—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ, –∫–∞–∫ –≤ backfill
    flat["area_id"] = v.get("area", {}).get("id")
    flat["employer_id"] = v.get("employer", {}).get("id")
    flat["role_id"] = roles[0].get("id") if roles else None
    return flat '''

records = [flatten_vacancy(v) for v in all_vacancies]

# --- –ù–û–í–û–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ records, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è FinalDF –∏–∑ backfill ---
if records:
    # –°–æ–∑–¥–∞—ë–º DataFrame –∏–∑ records
    df_temp = pd.DataFrame(records)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ FinalDF
    FinalRecords = (df_temp
        .astype({
            "salary_from": "Int64",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º nullable integer
            "salary_to": "Int64",
            "id": "int64", # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ id int64
            # area_id –∏ employer_id –º–æ–≥—É—Ç –±—ã—Ç—å NaN, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º Int64 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –∏–ª–∏ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å
            # "area_id": "Int64", # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ Int64
            # "employer_id": "Int64" # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        })
        .drop(columns=['area_id', 'employer_id', 'role_id'], errors='ignore') # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        .drop_duplicates() # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        .assign(salary_gross=lambda x: x["salary_gross"].map({
            True: True,
            False: False,
            "true": True,
            "false": False,
            None: None,
            "True": True, # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ API –≤–µ—Ä–Ω—ë—Ç —Å—Ç—Ä–æ–∫—É
            "False": False # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        }).astype("boolean")) # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–∏–ø—É boolean
    )
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è upsert
    records = FinalRecords.to_dict('records')
    
    # print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(records)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ (–±—ã–ª–æ {len(all_vacancies)} –¥–æ –æ—á–∏—Å—Ç–∫–∏).") # –£–±—Ä–∞–Ω–æ
else:
    # print("üì≠ –ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ –≤—á–µ—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.") # –£–±—Ä–∞–Ω–æ
    pass # –ü—Ä–æ—Å—Ç–æ –Ω–µ –¥–µ–ª–∞–µ–º –Ω–∏—á–µ–≥–æ, –µ—Å–ª–∏ records –ø—É—Å—Ç–æ–π


if records:
    try:
        supabase.table("hh_vacancies").upsert(records, on_conflict="id").execute()
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(records)} –≤–∞–∫–∞–Ω—Å–∏–π –≤ Supabase")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Supabase: {e}")
else:
    print("üì≠ –ù–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ –≤—á–µ—Ä–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.")
